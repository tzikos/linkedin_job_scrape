{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import openai\n",
    "import re\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"\"\"We are a growing group of 190+ talented people, spread over three continents and united by one common mission: To improve efficiency in shipping through transparency and data-driven decisions.\n",
    "\n",
    "Being at the forefront of a movement that's leading to a new digital era for shipping, we continuously set ambitious goals that often produce complex challenges and drive us to constantly innovate.\n",
    "\n",
    "Each day at MarineTraffic presents numerous opportunities to develop skills, share knowledge and have fun. We are an equal opportunity employer that celebrates diversity and is committed to creating an inclusive environment for all employees, one that is fair and honest and gives our people the confidence to be bold, to try new things and to grow.\n",
    "\n",
    "As a result of our rapid growth, we are looking for a talented Data Analyst to extract hidden insights from our vast amount of data, enable informed decision-making and productionise analytical output. She/he will be working closely with the Product and Data Science teams, be actively involved in any step of the relevant data lifecycle (collection, maintenance, evaluation, processing, transformation) and play a major role in analysing and interpreting the data to yield meaningful conclusions and targeted actions.\n",
    "\n",
    "Responsibilities:\n",
    "Perform exploratory, explanatory & statistical analysis to extract robust findings from data and provide decision-making insights\n",
    "Evaluate the performance of analytical/Data Science models & products\n",
    "Work with programming analytical tools and be involved in the productionisation of algorithms, metrics and data insights\n",
    "Evaluate new or existing data sources & data models\n",
    "Perform Q/A on data and improve data procedures\n",
    "Undertake projects requiring data collection and processing from heterogeneous sources\n",
    "Design dashboards, generate reports and meaningful insights\n",
    "Build expertise in the maritime industry through data and market understanding\n",
    "Actively participate in weekly Team meetings involving Product Managers, Data Scientists and Data Engineers\n",
    "Analyse and effectively communicate results and findings with internal and external stakeholders\n",
    "\n",
    "Requirements\n",
    "\n",
    "Required\n",
    "Degree in a related field such as Mathematics, Statistics, Engineering or Computer Science\n",
    "Strong analytical skills, problem-solving mindset & attention to detail\n",
    "Good knowledge of probability and statistics principles (data collection, sampling, distributions, hypothesis testing, point/interval estimation etc.)\n",
    "Proven experienced with Python and relevant libraries\n",
    "Knowledge of SQL\n",
    "Familiarity/experience with data visualisation tools (i.e. Tableau, Python visualisation libraries)\n",
    "At least 2 years of experience in a similar position\n",
    "\n",
    "Desired\n",
    "Familiarity with the Maritime Industry\n",
    "Familiarity with Big Data technologies and frameworks (AWS, Data Lakes, Warehousing)\n",
    "Understanding of basic Data Science principles\n",
    "\n",
    "Benefits\n",
    "\n",
    "What's in it for you? In MarineTraffic our people have the freedom to learn, grow, and be themselves.\n",
    "Work in an international, dynamic and pleasant environment, at a Great Place to Work-Certifiedâ„¢ growing company\n",
    "Remote work flexibility. Opportunity to work from the office, hybrid, or remotely\n",
    "Huge room for creativity and innovation\n",
    "Continuous learning including unlimited access to an online training platform\n",
    "Career development and growth opportunities\n",
    "Attractive Remuneration based on a job grading system\n",
    "Private Medical & Life Insurance\n",
    "Unlimited access to Mental Health Platform\n",
    "Sponsored wellbeing activities such as free on-site/online fitness activities\n",
    "\n",
    "If you feel you are a genuine fit for this role, which is both challenging and fun, we would like to hear from you.\n",
    "\n",
    "Get your career on course by joining a globally recognised industry leader. Apply now.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"\"\"Are you interested in working with a leading education technology player, the global leader in the assessment and certification of professional skills industry with a presence in more than 200 countries worldwide? If so, this is the chance to apply now! ðŸ“¥\n",
    "\n",
    "PeopleCert is looking for a Junior Data Scientist. The successful candidate will work directly alongside data scientists to identify patterns for software optimization, cost reduction, services improvement, data monetization, and market analysis. You will work with key stakeholders such as Sales & Marketing, Finance, and Accounting, Procurement and Logistics, Security, Operations, and Software Development leadership.\n",
    "\n",
    "As a Junior Data Scientist, your tasks will include the following:\n",
    "Accelerate data analysis through the development and application of efficient machine-learning models\n",
    "Visualize quality metrics in the areas of software development, finance, sales, marketing, operations, and security across a highly varied series of real-world scenarios\n",
    "Establish ETL (Extract, Transform and Load) and/or ELT pipelines between a wide variety of data input sources and output targets\n",
    "Educate key stakeholders in interpreting all visualized metrics\n",
    "Contribute to the data science technical roadmap of the DMO\n",
    "Contribute to Power BI data models, BI reports, and data science deliverables.\n",
    "Serve ad-hoc internal data analysis as-a-service requests\n",
    "Contribute to the establishment of an internal cross-functional data science community of practice\n",
    "Follow best practices in secure software development and comply with DMO software development guidelines\n",
    "Report on performance and security issues and suggest improvements\n",
    "Update relevant documentation in MS Teams\n",
    "\n",
    "What we look for:\n",
    "Undergraduate and graduate degrees combining knowledge in the areas of Computer Science and Business Management.\n",
    "Excellent command of the English language (C2 level certification desired, LanguageCert C2 LTE or C2 IESOL certificate would be a plus) and excellent interpersonal, verbal, and written communication skills.\n",
    "Minimum 1 year of working experience or related academic experience (masterâ€™s degree) in software development and analytics within commonly used programming languages like Python or equivalent\n",
    "Experience using data visualization tools such as Microsoft Power BI\n",
    "Experience with cloud technologies (MS Azure is preferred)\n",
    "Experience with big data technologies such as Apache Spark and Databricks\n",
    "Experience with Machine learning methods (Regression, classification) and statistical methods.\n",
    "Experience working within an agile environment\n",
    "Strong commitment to quality and delivery timelines, proactive, team player.\n",
    "\n",
    "What we offer:\n",
    "Competitive remuneration package\n",
    "Work in an international, dynamic and fun atmosphere\n",
    "Two free vouchers for all certifications from PeopleCert's Portfolio per year for all employees\n",
    "Complimentary coffee and tea in all our premises\n",
    "Huge learning experience in using best practices and global environment\n",
    "Constant personal and professional development\n",
    "100% Virtual Hiring Process\n",
    "\n",
    "If you want to become a member of our international, dynamic and agile team that creates world leading software products, then we should certainly like to hear from you!\n",
    "\n",
    "About PeopleCert\n",
    "\n",
    "PeopleCert is a global leader in assessment and certification of professional skills, partnering with multi-national organizations and government bodies for the development & delivery of standardized exams. Delivering exams across 200 countries and in 25 languages over its state-of-the-art assessment technology, PeopleCert enables professionals to boost their careers and realize their life ambitions.\n",
    "\n",
    "Quality, Innovation, Passion, Integrity are the core values which guide everything we do.\n",
    "\n",
    "Our offices in UK, Greece, and Cyprus boast a culture of diversity, where everyone is different, yet everyone fits in. All of us at PeopleCert are committed to the reflection of the diversity and inclusion of our customers and the communities in which we do business.\n",
    "\n",
    "Working on Home Office (HO) Secure English Language Tests (SELTs)\n",
    "\n",
    "Any person who is engaged by PeopleCert to work on the SELT service must undergo a Background Check (the results of which must be acceptable to PeopleCert and the HO) prior to commencing their SELT duties. All SELT personnel will be required to complete a declaration (provided by PeopleCert) where the existence of any criminal record and/or bankruptcy must be declared.\n",
    "If working on the SELT service in the UK, background checks will include:\n",
    "A basic or enhanced Disclosure Barring Service (DBS) check\n",
    "Right to Work in the UK check (including nationality, identity and place of residence)\n",
    "HO security check (Baseline Personnel Security Standard (BPSS) or Counter Terrorist Check (CTC)\n",
    "Financial background check\n",
    "Employment reference check.\n",
    "If working on the SELT service anywhere in the world (outside of the UK) personnel will undergo background checks that are equivalent to those stated for the UK.\n",
    "In addition, if personnel are required to speak to SELT candidates they must be appropriately skilled in English language and, where SELT services are provided anywhere in the world (outside of the UK), the official language of the relevant country.\n",
    "\n",
    "All applications will be treated with strict confidentiality.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"\"\"Sportradar is the leading global provider of sports betting and sports entertainment products and services. Since 2001, we have occupied a unique position at the intersection of the sports, media and betting industries; providing sports federations, news media, consumer platforms and sports betting operators with a range of solutions to help grow their business.\n",
    "\n",
    "\n",
    "In April 2022, Sportradar acquired Vaix, a company who creates deeply integrated and powerful corporate AI solutions, enabling B2C internet businesses to utilize the power of machine learning for their customers and operations.\n",
    "\n",
    "\n",
    "We are looking for a passionate data analyst with excellent statistics and SQL skills to join our technical team. The role also includes business intelligence and team leading responsibilities. This is a mid-level role, so individuals with related working experience or exceptional educational background are encouraged to apply.\n",
    "\n",
    "\n",
    "The role entails:\n",
    "\n",
    "\n",
    "Obtain, clean and analyse data about the performance of Vaix products in AB tests\n",
    "Create customer dashboards\n",
    "Identify and explain performance issues and suggest improvements and solutions\n",
    "Collaborate with your team members to continually improve working processes and share knowledge\n",
    "\n",
    "Requirements:\n",
    "\n",
    "\n",
    "Excellent knowledge of SQL\n",
    "Bachelor degree in Mathematics/Statistics (or proven strong related background/experience)\n",
    "Good command of the English language, in spoken and written forms and excellent communication skills\n",
    "Experience in the iGaming domain is a plus\n",
    "Knowledge of Python, R or a similar language/tool for data analysis is a plus\n",
    "Strong \"get things done the right way\" attitude\n",
    "Strong willingness to learn new technologies and work on challenging problems\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 = \"\"\"At Alpha Bank, we are shaping the future of banking in Greece.\n",
    "\n",
    "\n",
    "Through our large-scale Transformation Program, we are changing the way we operate, the way we deliver results and the way we service our Customers.\n",
    "\n",
    "\n",
    "â€¢ We understand our Customersâ€™ needs and design experiences around them.\n",
    "\n",
    "â€¢ We work in partnership and invite diversity of skills and perspectives.\n",
    "\n",
    "â€¢ We are forward-thinking and drive continuous improvement.\n",
    "\n",
    "â€¢ We make things happen; we execute quickly and focus on what is essential.\n",
    "\n",
    "\n",
    "If you are a change enthusiast who sets ambitious goals and works with a sense of purpose, we want to get to know you!\n",
    "\n",
    "\n",
    "Join our team and #be_part_of_tomorrow\n",
    "\n",
    "\n",
    "#AlphaBank #TheAlphaBlueprint #Tomorrow\n",
    "\n",
    "\n",
    "The Data Scientist will be placed in the Customer Value and Data Management Division of Alpha Bank. He/she will work closely with the various Divisions of the Bank to understand their challenges in depth and will use data to propose solutions and support decision-making. The ideal candidate should have excellent collaboration skills, should be able to communicate key data insights to involved stakeholders and should demonstrate eagerness to search for new things and develop his/her knowledge further.\n",
    "\n",
    "\n",
    "What you will be doing\n",
    "\n",
    "\n",
    "â€¢ Engage with business teams to find opportunities, to understand requirements and to translate those requirements into technical solutions.\n",
    "\n",
    "â€¢ Support the Project Manager in the preparation of delivery plans, identifying data and technology requirements.\n",
    "\n",
    "â€¢ Build machine learning models through all phases of development, from design through training, evaluation, validation and implementation, applying tried-and-true techniques or developing custom algorithms, as each business problem demands.\n",
    "\n",
    "â€¢ Collaborate with data engineers, Business Intelligence (BI) analysts and platform owners to integrate the results of the machine learning models in real-time and/or batch solutions.\n",
    "\n",
    "â€¢ Monitor model performance in production and assess the need for model improvement or decommissioning.\n",
    "\n",
    "â€¢ Research new data science technologies and methods to improve the technical capabilities of the team.\n",
    "\n",
    "\n",
    "What you need to have\n",
    "\n",
    "\n",
    "â€¢ A Bachelorâ€™s degree in Computer Science, Statistics, Mathematics, Economics or in any other related field of study. A Masterâ€™s degree in a relevant field will be considered a plus.\n",
    "\n",
    "â€¢ At least four (4) years of professional experience in the design, implementation and productization of advanced analytics solutions.\n",
    "\n",
    "â€¢ Knowledge of advanced analytics algorithms for classification, regression, clustering, anomaly detection, forecasting, optimization and Natural Language Processing (NLP).\n",
    "\n",
    "â€¢ Strong programming skills in Python or in a similar programming language.\n",
    "\n",
    "â€¢ Knowledge of SPSS Modeler or similar data science solutions.\n",
    "\n",
    "â€¢ Understanding of the machine learning model lifecycle and Machine Learning Operations (MLOps) practices.\n",
    "\n",
    "â€¢ Familiarity with data modeling and data management concepts will be considered a plus.\n",
    "\n",
    "â€¢ Experience in the financial services sector will be considered an asset.\n",
    "\n",
    "â€¢ Excellent communication skills, along with the ability to present complex solutions in a clear and simple manner.\n",
    "\n",
    "â€¢ Willingness to put effort and to demonstrate commitment to achieve results.\n",
    "\n",
    "â€¢ Eagerness to step out of oneâ€™s comfort zone, so as to learn and push colleagues to do the same.\n",
    "\n",
    "â€¢ Openness to taking on new challenges and driving change in the Organization.\n",
    "\n",
    "â€¢ Excellent command of the English and the Greek language (both written and spoken).\n",
    "\n",
    "\n",
    "What we offer\n",
    "\n",
    "\n",
    "Itâ€™s all about our people. At Alpha Bank, you will enjoy:\n",
    "\n",
    "\n",
    "â€¢ An opportunity to join the most robust financial institution in Greece with a leading role in the Greek economy.\n",
    "\n",
    "â€¢ A friendly, modern, collaborative and award-winning work environment (Piraeus Port Plaza) that supports taking initiative and action.\n",
    "\n",
    "â€¢ A culture that centers around learning and continuous development and encourages everyone to bring their best self to work.\n",
    "\n",
    "â€¢ The opportunity to challenge your thinking through your participation in complex tasks and transformation projects.\n",
    "\n",
    "â€¢ A competitive salary and benefits.\n",
    "\n",
    "â€¢ An annual bonus scheme based on performance.\n",
    "\n",
    "â€¢ A buddy to provide support with onboarding.\n",
    "\n",
    "â€¢ Access to LinkedIn Learning and to continuous training.\n",
    "\n",
    "\n",
    "Alpha Bank offers a remote interview process and a work-from-home scheme during the implementation of the current social distancing measures.\n",
    "\n",
    "\n",
    "All applications will be acknowledged and treated in utmost confidence.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = [text1,text2,text3,text4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(texts):\n",
    "    job_titles = []\n",
    "    requirements = []\n",
    "    for text in text_list:\n",
    "        prompt = 'Tell me only the name and job requirements out of this job description: ' + text\n",
    "        response = openai.Completion.create(\n",
    "            model=\"text-davinci-003\",\n",
    "            prompt=prompt,\n",
    "            temperature=0.9,\n",
    "            max_tokens=300,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0.6,\n",
    "        )\n",
    "        summary = response[\"choices\"][0][\"text\"].replace('\\n','')\n",
    "        time.sleep(20)\n",
    "        prompt1 = 'Tell me only the name of the job in this text: ' + summary\n",
    "        response = openai.Completion.create(\n",
    "            model=\"text-davinci-003\",\n",
    "            prompt=prompt1,\n",
    "            temperature=0.9,\n",
    "            max_tokens=300,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0.6,\n",
    "        )\n",
    "        summary1 = response[\"choices\"][0][\"text\"].replace('\\n','')\n",
    "        job_titles.append(summary1)\n",
    "        time.sleep(20)\n",
    "        prompt2 = 'Tell me only the job requirements in this text with as few words as possible: ' + summary\n",
    "        response = openai.Completion.create(\n",
    "            model=\"text-davinci-003\",\n",
    "            prompt=prompt2,\n",
    "            temperature=0.9,\n",
    "            max_tokens=300,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0.6,\n",
    "        )\n",
    "        summary2 = response[\"choices\"][0][\"text\"].replace('\\n','')\n",
    "        requirements.append(summary2)\n",
    "        time.sleep(20)\n",
    "    df = pd.DataFrame({'Job Title':job_titles,'Requirements':requirements})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = make_df(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Requirements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Degree, Analytical skills, Probability/Statist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Education, English, experience, data visualiza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>SQL, Mathematics/Statistics, English, iGaming,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alpha BankJob</td>\n",
       "      <td>Bachelor's degree, 4 yrs exp, analytics algori...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Job Title                                       Requirements\n",
       "0           Data Analyst  Degree, Analytical skills, Probability/Statist...\n",
       "1  Junior Data Scientist  Education, English, experience, data visualiza...\n",
       "2           Data Analyst  SQL, Mathematics/Statistics, English, iGaming,...\n",
       "3          Alpha BankJob  Bachelor's degree, 4 yrs exp, analytics algori..."
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_requirements = ''\n",
    "for i in df['Requirements']:\n",
    "    all_requirements = all_requirements + i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "clean = re.sub('[^A-Za-z0â€“9 ]|Experience|Strong|strong|check','',all_requirements)\n",
    "word_tokens = word_tokenize(clean)\n",
    "# converts the words in word_tokens to lower case and then checks whether \n",
    "#they are present in stop_words or not\n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "#with no lower case conversion\n",
    "filtered_sentence = []\n",
    "  \n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(filtered_sentence)):\n",
    "    k = filtered_sentence.count(filtered_sentence[i])\n",
    "    filtered_sentence[i] = [filtered_sentence[i],k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk = pd.DataFrame(filtered_sentence,columns=['word','times'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk = chk.sort_values('times',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['data', 'machine', 'skills', 'exp', 'Python', 'learning',\n",
       "       'English', 'Degree', 'Modeler', 'algorithms', 'analytics', 'SPSS',\n",
       "       'modeling', 'degree', 'mgmt', 'fin', 'services', 'comm', 'effort',\n",
       "       'yrs', 'iGaming', 'WillingnessBachelors', 'Attitude',\n",
       "       'ProbabilityStatistics', 'SQL', 'Data', 'Visualisation',\n",
       "       'Education', 'experience', 'visualization', 'cloud', 'big',\n",
       "       'agile', 'software', 'development', 'communicationSQL',\n",
       "       'MathematicsStatistics', 'Analytical', 'PythonR', 'EnglishGreek'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chk['word'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' (C2 level certification desired, LanguageCert C2 LTE or C2 IESOL certificate would be a plus)â€¢ Excellent interpersonal, verbal, and written communication skillsâ€¢ Minimum 1 year of working experience or related academic experience (masterâ€™s degree) in software development and analytics within commonly used programming languages like Python or equivalentâ€¢ Experience using data visualization tools such as Microsoft Power BIâ€¢ Experience with cloud technologies such as Amazon Web Services (AWS), Microsoft Azure, and/or GCPâ€¢ Experience with interactive query languages such as SQL and NoSQLâ€¢ Skill in using data manipulation tools such as Apache Sparkâ€¢ Working knowledge of Big Data systems and principles including distributed, real-time and batch-oriented data processingâ€¢ Exposure to machine learning and AI, such as supervised and unsupervised learning, clustering, anomaly detection, regression, and deep learning.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt3 = 'Which are all the job requirements from this text? :' + all_requirements\n",
    "response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=prompt3,\n",
    "    temperature=0.9,\n",
    "    max_tokens=300,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0.6,\n",
    ")\n",
    "summary3 = response[\"choices\"][0][\"text\"].replace('\\n','')\n",
    "summary3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.linkedin.com/jobs/collections/recommended/?currentJobId=3438314140\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_next_siblings(\"div\", class_='scaffold-layout__list-container')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m main_content \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m\"\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mjob-view-layout jobs-details\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[39m# Find the h2 element with the job title\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m job_title \u001b[39m=\u001b[39m main_content\u001b[39m.\u001b[39;49mfind(\u001b[39m\"\u001b[39m\u001b[39mh2\u001b[39m\u001b[39m\"\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mt-24 t-bold jobs-unified-top-card__job-title\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mtext\n\u001b[0;32m     13\u001b[0m \u001b[39m# Find the div element with the text\u001b[39;00m\n\u001b[0;32m     14\u001b[0m text \u001b[39m=\u001b[39m main_content\u001b[39m.\u001b[39mfind(\u001b[39m\"\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[0;32m     15\u001b[0m class_\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mjobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mtext\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Find the div with the specified class\n",
    "main_content = soup.find(\"div\", class_='scaffold-layout__list-container')\n",
    "\n",
    "# Find the h2 element with the job title\n",
    "job_title = main_content.find(\"h2\", class_=\"t-24 t-bold jobs-unified-top-card__job-title\").text\n",
    "\n",
    "# Find the div element with the text\n",
    "text = main_content.find(\"div\", \n",
    "class_=\"jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame from the variables\n",
    "df = pd.DataFrame({\"Job Title\": [job_title], \"Text\": [text]})\n",
    "\n",
    "# Print the data frame\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1ac784e6611aeeaf413d94574b37cc90047e3b8cf844a9d748eb46a89d6576d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
